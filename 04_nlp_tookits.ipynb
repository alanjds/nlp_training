{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Tookits\n",
    "\n",
    "Several Natural Language Processing Toolkits available for Python. Basic NLP functions provided (tokenization, PoS Tagging, Chunking, etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## [NLTK](http://www.nltk.org/) \n",
    "    * Most known Toolkit.\n",
    "    * Allows to build an NLP Pipeline and some applications\n",
    "    * Developed with teaching in mind, may not be the fast toolkit available, but the easiest to understand. \n",
    "    * It has some tools and models for Portuguese - <http://www.nltk.org/howto/portuguese_en.html>\n",
    "    * It is necessary to download models with nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Geladeira',\n",
       " u'Brastemp',\n",
       " u'c/',\n",
       " u'painel',\n",
       " u'branco-amarelo',\n",
       " u'.',\n",
       " u'Atualiza\\xe7\\xe3o',\n",
       " u'em',\n",
       " u'(',\n",
       " u'09/12/2015',\n",
       " u')',\n",
       " u'.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(u'Geladeira Brastemp c/ painel branco-amarelo. Atualização em (09/12/2015).', language='portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import mac_morpho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Jersei', u'N'), (u'atinge', u'V'), ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mac_morpho.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import floresta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('UTT+np', [Tree('>N+art', ['Um']), Tree('H+n', ['revivalismo']), Tree('N<+adj', ['refrescante'])]), Tree('STA+fcl', [Tree('SUBJ+np', [Tree('>N+art', ['O']), Tree('H+prop', ['7_e_Meio'])]), Tree('P+v-fin', ['\\xe9']), Tree('SC+np', [Tree('>N+art', ['um']), Tree('H+n', ['ex-libris']), Tree('N<+pp', [Tree('H+prp', ['de']), Tree('P<+np', [Tree('>N+art', ['a']), Tree('H+n', ['noite']), Tree('N<+adj', ['algarvia'])])])]), Tree('.', ['.'])]), ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floresta.parsed_sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## [Pattern](http://www.clips.ua.ac.be/pattern)\n",
    "\n",
    "* Pattern is a web mining module for the Python programming language.\n",
    "* It has tools for data mining (Google, Twitter and Wikipedia API, a web crawler, a HTML DOM parser), natural language processing (part-of-speech taggers, n-gram search, sentiment analysis, WordNet), machine learning (vector space model, clustering, SVM), network analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.en import tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'I', u'PRP'), (u'eat', u'VBP'), (u'pizza', u'NN'), (u'with', u'IN'), (u'a', u'DT'), (u'fork', u'NN'), (u'.', u'.')]\n",
      "pizza\n",
      "fork\n"
     ]
    }
   ],
   "source": [
    "s = \"I eat pizza with a fork.\"\n",
    "s = tag(s)\n",
    "print s\n",
    "for word, tag in s:\n",
    "    if tag == \"NN\": # Find all nouns in the input string.\n",
    "        print word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pattern.web import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter = Twitter(language='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Zaga_Silos: Dilma quer cobrar do povo um ajuste fiscal, sendo que apenas o desviado no Petrolão daria pra fazer dezenas de ajustes fisc…\n",
      "RT @o_antagonista: A campanha de Dilma custou um bilhão de reais, mas \"só\" R$ 300 milhões foram declarados https://t.co/szqs23Ov5z https://…\n",
      "Dilma deverá centrar sua política econômica(?) na expansão do crédito e do consumo, enquanto o Banco Central estuda elevar os juros. PODE?\n",
      "@diogomainardi e você tem dúvida? Todos recebem. Aecio, Dilma, Lula... Ou vanos ser ingênuos ?\n",
      "RT @SenadoFederal: Dilma sanciona lei que regulariza repatriação de dinheiro de brasileiro no exterior https://t.co/yXVH2if6TM\n",
      "RT @rodolfogbw: Dilma viola a Lei de Responsabilidade Fiscal e a punição é severa...para nós! https://t.co/mKKndWhgKy\n",
      "RT @Ricamconsult: A Dilma está tornando os BRs + fortes.Há 5 anos, eram necessárias 2 pessoas p carregar R$100 em compras de supermercado; …\n",
      "hhahahaahahahaha\n",
      "\n",
      "Dilma e as Dilmarchinhas de Carnaval https://t.co/E14YOV7JFQ via @YouTube\n",
      "RT @diogomainardi: A Lava Jato deve investigar se João Santana recebeu dinheiro sujo para a campanha de Dilma https://t.co/jY8mzm2dlR https…\n",
      "@leozoera @nntclayton @JornalOGlobo Mas falar que tudo é culpa da dilma é mais fácil né\n"
     ]
    }
   ],
   "source": [
    "for tweet in twitter.search('Dilma', cached=False):\n",
    "    print tweet.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## [TextBlob](https://textblob.readthedocs.org/en/dev/)\n",
    "\n",
    "* It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
    "* As the website says, TextBlob stands on the giant shoulders of NLTK and pattern, and plays nicely with both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "text = 'Geladeira Brastemp 2 Portas Branca com sensor de porta aberta'\n",
    "blob = TextBlob(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'pt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Geladeira', u'NNP'),\n",
       " (u'Brastemp', u'NNP'),\n",
       " (u'2', u'CD'),\n",
       " (u'Portas', u'NNP'),\n",
       " (u'Branca', u'NNP'),\n",
       " (u'com', u'NN'),\n",
       " (u'sensor', u'NN'),\n",
       " (u'de', u'IN'),\n",
       " (u'porta', u'FW'),\n",
       " (u'aberta', u'NN')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList([u'geladeira brastemp', u'portas branca', u'com sensor', u'porta aberta'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## [polyglot](http://polyglot.readthedocs.org/l)\n",
    "\n",
    "Polyglot is a natural language pipeline that supports massive multilingual applications.\n",
    "\n",
    "Features:\n",
    "\n",
    "* Tokenization (165 Languages)\n",
    "* Language detection (196 Languages)\n",
    "* Named Entity Recognition (40 Languages)\n",
    "* Part of Speech Tagging (16 Languages)\n",
    "* Sentiment Analysis (136 Languages)\n",
    "* Word Embeddings (137 Languages)\n",
    "* Morphological analysis (135 Languages)\n",
    "* Transliteration (69 Languages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path used for polyglot downloaded data\n",
    "import polyglot\n",
    "polyglot.data_path = '/usr/share/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'tsne2',\n",
       " u'sentiment2',\n",
       " u'sgns2',\n",
       " u'morph2',\n",
       " u'transliteration2',\n",
       " u'counts2',\n",
       " u'pos2',\n",
       " u'ner2',\n",
       " u'embeddings2']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from polyglot.downloader import downloader\n",
    "downloader.supported_tasks(lang=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from polyglot.text import Text, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = Text(u'Geladeira Brastemp c/ painel branco-amarelo. Atualização em (09/12/2015).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "Geladeira       NOUN\n",
      "Brastemp        NUM\n",
      "c               NUM\n",
      "/               PUNCT\n",
      "painel          NOUN\n",
      "branco          ADJ\n",
      "-               PUNCT\n",
      "amarelo         ADJ\n",
      ".               PUNCT\n",
      "Atualização     NOUN\n",
      "em              ADP\n",
      "(               PUNCT\n",
      "09              NUM\n",
      "/               PUNCT\n",
      "12              NUM\n",
      "/               PUNCT\n",
      "2015            NUM\n",
      ")               PUNCT\n",
      ".               PUNCT\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors (Synonms) of geladeira\n",
      "------------------------------\n",
      "gaveta          \n",
      "bochecha        \n",
      "estante         \n",
      "fornalha        \n",
      "jangada         \n",
      "barricada       \n",
      "Disneylândia    \n",
      "taberna         \n",
      "taverna         \n",
      "lavanderia      \n",
      "\n",
      "\n",
      "The first 10 dimensions out the 256 dimensions\n",
      "\n",
      "[-1.71507478 -0.63970172 -0.40256602  0.10979888  0.92080826 -0.13696\n",
      "  0.23301034 -0.11777839 -0.1058483   0.22535691]\n"
     ]
    }
   ],
   "source": [
    "word = Word(u'geladeira', language=\"pt\")\n",
    "print(\"Neighbors (Synonms) of {}\".format(word)+\"\\n\"+\"-\"*30)\n",
    "for w in word.neighbors:\n",
    "    print(\"{:<16}\".format(w))\n",
    "print(\"\\n\\nThe first 10 dimensions out the {} dimensions\\n\".format(word.vector.shape[0]))\n",
    "print(word.vector[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList([u'in', u'felic', u'idade'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = Word(u'infelicidade')\n",
    "word.morphemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Polarity\n",
      "------------------------------\n",
      "Apesar           0\n",
      "de              -1\n",
      "interessante     1\n",
      ",                0\n",
      "o                0\n",
      "produto          0\n",
      "é                0\n",
      "caro            -1\n",
      "e                0\n",
      "deixa            0\n",
      "a                0\n",
      "desejar          1\n",
      ".                0\n",
      "Não              0\n",
      "recomendo        0\n"
     ]
    }
   ],
   "source": [
    "text = Text('Apesar de interessante, o produto é caro e deixa a desejar. Não recomendo')\n",
    "print(\"{:<16}{}\".format(\"Word\", \"Polarity\")+\"\\n\"+\"-\"*30)\n",
    "for w in text.words:\n",
    "    print(\"{:<16}{:>2}\".format(w, w.polarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## [NLPNet](http://nilc.icmc.usp.br/nlpnet/)\n",
    "\n",
    "* nlpnet is a Python library for Natural Language Processing tasks based on neural networks. \n",
    "* It performs part-of-speech tagging and semantic role labeling.\n",
    "* It was developed at [NILC](http://nilc.icmc.usp.br/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'Geladeira', u'N'),\n",
       "  (u'Brastemp', u'N'),\n",
       "  (u'c/', u'N'),\n",
       "  (u'painel', u'N'),\n",
       "  (u'branco-amarelo', u'ADJ'),\n",
       "  (u'.', u'PU')],\n",
       " [(u'Atualiza\\xe7\\xe3o', u'N'),\n",
       "  (u'em', u'PREP'),\n",
       "  (u'(', u'PU'),\n",
       "  (u'09/12/2015', u'N'),\n",
       "  (u')', u'PU'),\n",
       "  (u'.', u'PU')]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nlpnet\n",
    "nlpnet.set_data_dir(str('/usr/share/nlpnet_data/'))\n",
    "tagger = nlpnet.POSTagger()\n",
    "tagger.tag(u'Geladeira Brastemp c/ painel branco-amarelo. Atualização em (09/12/2015).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'roeu',\n",
       "  {u'A0': [u'O', u'rato'],\n",
       "   u'A1': [u'a', u'roupa', u'do', u'rei', u'de', u'Roma'],\n",
       "   u'AM-TMP': [u'em', u'abril'],\n",
       "   u'V': [u'roeu']})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = nlpnet.SRLTagger()\n",
    "sent = tagger.tag(u'O rato roeu a roupa do rei de Roma em abril.')[0]\n",
    "sent.arg_structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## [spaCy](https://spacy.io/)\n",
    "\n",
    "* spaCy is a library for industrial-strength natural language processing in Python and Cython. \n",
    "* It features state-of-the-art speed and accuracy, a concise API, and great documentation. \n",
    "* English Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## [MontyLingua](http://alumni.media.mit.edu/~hugo/montylingua/)\n",
    "\n",
    "* MontyLingua is a free, commonsense-enriched, end-to-end natural language understander for English.\n",
    "* The last update on the library was in 2004\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "\n",
    "## Others\n",
    "* [Aelius](http://sourceforge.net/projects/aelius/files/) - Aelius Brazilian Portuguese POS-Tagger and Corpus Annotation Tool. The tool it not available on pip and havely depends on third-based programs in java.\n",
    "\n",
    "* [PyNLPI](http://pythonhosted.org/PyNLPl/) - Python Natural Language Processing Library (PyNLPl, pronounced as “pineapple”). The library offers a wide variety of modules for various NLP tasks.\n",
    "\n",
    "* [PyPLN](http://pypln.org/) - PyPLN is a platform for processing and extracting useful information from text. It was conceived to run in the cloud, scale quickly and be easy to us. (Authors from FGV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
